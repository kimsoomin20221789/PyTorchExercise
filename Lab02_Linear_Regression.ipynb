{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgLbF+miBkikSiQJzyp99P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsoomin20221789/PyTorchExercise/blob/main/Lab02_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BnYf5m-ilVXs"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "rwx9BTd2Iv3t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# W, b 초기화 (학습할 tensor들 초기화)\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "dHY6nM18I7iC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 정의\n",
        "import torch.optim as optim\n",
        "optimizer = optim.SGD([W, b], lr = 0.01)"
      ],
      "metadata": {
        "id": "ZTYoCrRvJOmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 3000\n",
        "for epoch in range(1, nb_epochs+1):\n",
        "  hypothesis = x_train*W + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward() # backward()로 gradient 계산\n",
        "  optimizer.step() #step으로 gradient 개선"
      ],
      "metadata": {
        "id": "93EkPAk-JXni"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradient란 공간의 기울기를 의미합니다. gradient의 방향은 함수값이 큰 쪽으로 방향을 가지게 됩니다.\n",
        "\n",
        "따라서 cost를 backward 함수를 사용하면 자동 미분을 하여, gradient 값을 계산하게 됩니다.\n",
        "\n",
        "optimizer(SGD = 기울기 하강 = 최소 손실) 를 사용하여 W와 b의 값을 갱신합니다."
      ],
      "metadata": {
        "id": "4qwQlleTL6zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(W)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_EqzrRlKExh",
        "outputId": "47a9180d-7b76-4e02-95a4-2338828f0b7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0000], requires_grad=True)\n",
            "tensor([4.8882e-05], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}